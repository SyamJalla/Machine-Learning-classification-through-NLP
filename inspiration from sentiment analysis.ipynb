{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was given data set by one startup as technical assignment as a part of interview process.\n",
    "Its a classification problem.\n",
    "Training data has 603201 observations\n",
    "Testing data has 442041 observations /\n",
    "And owning to some errors due to memory i couldnot complete the assignment.\n",
    "So I decided to use sample of data and apply the same approach look how the model is performing for the sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the original data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_df = pd.read_csv('C:/Users/smartsyam/Desktop/unitednations/train.csv')\n",
    "UN_test_df = pd.read_csv('C:/Users/smartsyam/Desktop/unitednations/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storeId</th>\n",
       "      <th>url</th>\n",
       "      <th>additionalAttributes</th>\n",
       "      <th>breadcrumbs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>http://www.walmart.com/ip/best-of-toto%3A-pian...</td>\n",
       "      <td>Contributed by=Toto;Format=Paperback;Number of...</td>\n",
       "      <td>books &gt; art music &amp; photography &gt; music</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best buy &gt; computers &amp; tablets &gt; computer card...</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>https://www.walmart.com/ip/34441317</td>\n",
       "      <td>Performer=Cult Of Youth;Record Label=Vinyl;1.=...</td>\n",
       "      <td>music on cd or vinyl &gt; rock music on cd or vin...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>https://www.overstock.com/Books-Movies-Music-G...</td>\n",
       "      <td>Format=Paperback;Copyright Year=2000;Publisher...</td>\n",
       "      <td>books &amp; media &gt; books &gt; cooking &amp; food books &gt;...</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>http://www.target.com/p/amore-version-ii/-/A-1...</td>\n",
       "      <td>Store Item Number (DPCI)=244-48-2721;Origin=Ma...</td>\n",
       "      <td>target &gt; movies, music &amp; books &gt; music &gt; class...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storeId                                                url  \\\n",
       "0      23  http://www.walmart.com/ip/best-of-toto%3A-pian...   \n",
       "1     NaN                                                NaN   \n",
       "2      23                https://www.walmart.com/ip/34441317   \n",
       "3      26  https://www.overstock.com/Books-Movies-Music-G...   \n",
       "4      22  http://www.target.com/p/amore-version-ii/-/A-1...   \n",
       "\n",
       "                                additionalAttributes  \\\n",
       "0  Contributed by=Toto;Format=Paperback;Number of...   \n",
       "1                                                NaN   \n",
       "2  Performer=Cult Of Youth;Record Label=Vinyl;1.=...   \n",
       "3  Format=Paperback;Copyright Year=2000;Publisher...   \n",
       "4  Store Item Number (DPCI)=244-48-2721;Origin=Ma...   \n",
       "\n",
       "                                         breadcrumbs  label  \n",
       "0            books > art music & photography > music  books  \n",
       "1  best buy > computers & tablets > computer card...   rest  \n",
       "2  music on cd or vinyl > rock music on cd or vin...  music  \n",
       "3  books & media > books > cooking & food books >...  books  \n",
       "4  target > movies, music & books > music > class...  music  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data has four features and one target variable. Additionalattributes and breacrumbs are the most information\n",
    "Bearing variables. Idea was to combine these two and use these as featureset for building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storeId</th>\n",
       "      <th>url</th>\n",
       "      <th>additionalAttributes</th>\n",
       "      <th>breadcrumbs</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baby products &gt; bathing &amp; skin care &gt; washclot...</td>\n",
       "      <td>8589934592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online shopping  &gt;  home &amp; garden  &gt;  art gal...</td>\n",
       "      <td>8589934593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home goods &gt; kitchen &amp; dining &gt; table linens &amp;...</td>\n",
       "      <td>8589934594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11320</td>\n",
       "      <td>8589934595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tools &amp; home improvement &gt; kitchen &amp; bath fixt...</td>\n",
       "      <td>8589934596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storeId  url additionalAttributes  \\\n",
       "0     NaN  NaN                  NaN   \n",
       "1     NaN  NaN                  NaN   \n",
       "2     NaN  NaN                  NaN   \n",
       "3     NaN  NaN                  NaN   \n",
       "4     NaN  NaN                  NaN   \n",
       "\n",
       "                                         breadcrumbs          id  \n",
       "0  baby products > bathing & skin care > washclot...  8589934592  \n",
       "1   online shopping  >  home & garden  >  art gal...  8589934593  \n",
       "2  home goods > kitchen & dining > table linens &...  8589934594  \n",
       "3                                              11320  8589934595  \n",
       "4  tools & home improvement > kitchen & bath fixt...  8589934596  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing data has no label varibale. but one additional id varibale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As i said earlier idea was to combine the tokens present in two features additionalattribues and breadcrumbs and use them as training fetures. \\\n",
    "First corpus is prepared by combing all the present in these two features and taking most frequents tokens from this\n",
    "corpus. And then for each observation we look for each token if its a part of this corpus, it will be true if its present\n",
    "in corpus and false if it is not present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taking a sample of 10000 observations from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample = UN_train_df.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "storeId                  True\n",
       "url                      True\n",
       "additionalAttributes     True\n",
       "breadcrumbs              True\n",
       "label                   False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_sample.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "storeId                 6426\n",
       "url                     6426\n",
       "additionalAttributes    6426\n",
       "breadcrumbs               58\n",
       "label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_sample.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest      6426\n",
       "books     1607\n",
       "music     1050\n",
       "videos     917\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest      389250\n",
       "books      95811\n",
       "music      59996\n",
       "videos     58144\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the distribution different types of labels in sample. the distirbution is nearly same as orginal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storeId</th>\n",
       "      <th>url</th>\n",
       "      <th>additionalAttributes</th>\n",
       "      <th>breadcrumbs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424478</th>\n",
       "      <td>6075</td>\n",
       "      <td>https://www.abebooks.com/servlet/BookDetailsPL...</td>\n",
       "      <td>Book Condition=Fair;Binding=Paperback;Title=Th...</td>\n",
       "      <td>henry james</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191839</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best buy &gt; cell phones &gt; cell phone accessorie...</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333091</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11320</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200921</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>office &gt; office supplies &gt; office organization...</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486321</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best buy &gt; computers &amp; tablets &gt; computer card...</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       storeId                                                url  \\\n",
       "424478    6075  https://www.abebooks.com/servlet/BookDetailsPL...   \n",
       "191839     NaN                                                NaN   \n",
       "333091     NaN                                                NaN   \n",
       "200921     NaN                                                NaN   \n",
       "486321     NaN                                                NaN   \n",
       "\n",
       "                                     additionalAttributes  \\\n",
       "424478  Book Condition=Fair;Binding=Paperback;Title=Th...   \n",
       "191839                                                NaN   \n",
       "333091                                                NaN   \n",
       "200921                                                NaN   \n",
       "486321                                                NaN   \n",
       "\n",
       "                                              breadcrumbs  label  \n",
       "424478                                        henry james  books  \n",
       "191839  best buy > cell phones > cell phone accessorie...   rest  \n",
       "333091                                              11320   rest  \n",
       "200921  office > office supplies > office organization...   rest  \n",
       "486321  best buy > computers & tablets > computer card...   rest  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storeId</th>\n",
       "      <th>url</th>\n",
       "      <th>additionalAttributes</th>\n",
       "      <th>breadcrumbs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3574</td>\n",
       "      <td>3574</td>\n",
       "      <td>3574</td>\n",
       "      <td>9942</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>3570</td>\n",
       "      <td>3560</td>\n",
       "      <td>4574</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>23</td>\n",
       "      <td>https://www.walmart.com/ip/Frente-a-Frente/269...</td>\n",
       "      <td>edition=Audio CD</td>\n",
       "      <td>music</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>266</td>\n",
       "      <td>6426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       storeId                                                url  \\\n",
       "count     3574                                               3574   \n",
       "unique      11                                               3570   \n",
       "top         23  https://www.walmart.com/ip/Frente-a-Frente/269...   \n",
       "freq       844                                                  2   \n",
       "\n",
       "       additionalAttributes breadcrumbs  label  \n",
       "count                  3574        9942  10000  \n",
       "unique                 3560        4574      4  \n",
       "top        edition=Audio CD       music   rest  \n",
       "freq                      4         266   6426  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UN_train_sample.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further variables has to be in string. so converting features additionalAttributes and breadcrumbs to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample['additionalAttributes'] = UN_train_sample['additionalAttributes'].astype(str)\n",
    "UN_train_sample['breadcrumbs'] = UN_train_sample['breadcrumbs'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing these varibales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample['AddAtt_token'] = UN_train_sample['additionalAttributes'].apply(nltk.word_tokenize)\n",
    "UN_train_sample['bread_token'] = UN_train_sample['breadcrumbs'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating corpus for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample['corpus'] = UN_train_sample['AddAtt_token']+UN_train_sample['bread_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the tokens which are of length 1 as these are mostly symbols and length 2 as i assumed two length words have no meaning also removing NAN words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample['corpus'] = UN_train_sample['corpus'].apply(lambda x: [item for item in x if len(item) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample['corpus'] = UN_train_sample['corpus'].apply(lambda x: [item for item in x if item != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all other features except corpus feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UN_train_sample = UN_train_sample.drop(['storeId','url','additionalAttributes','breadcrumbs','AddAtt_token','bread_token'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating corpus for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_corpus = []\n",
    "\n",
    "for x in UN_train_sample.corpus:\n",
    "    total_corpus.extend(x)\n",
    "    \n",
    "\n",
    "total_corpus = nltk.FreqDist(total_corpus)\n",
    "    \n",
    "corp_features = list(total_corpus.keys())[0:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took top 5000 most frequent tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making each training observation to a tuple of length 2 with one as a  corpus and other as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final_sample = list(zip(UN_train_sample.corpus, UN_train_sample.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for searching each token from the observation and then looking out in corpus. and making a dictionary with true if present and false if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in corp_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating feature sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_train_featuresets = [(find_features(corpus), label) for (corpus, label) in train_final_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diving the sample into training and testing data in the ratio of 0.8 and 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_sample = sample_train_featuresets[:8000]\n",
    "testing_sample = sample_train_featuresets[8000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing few libraries for algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy percent: 99.9\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_sample)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_sample))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB_classifier accuracy percent: 99.0\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_sample)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_sample))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 100.0\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_sample)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_sample))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 99.95\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_sample)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_sample))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy percent: 100.0\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_sample)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_sample))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So It is observed that even 100 percent accuracy is obtained for testing data. so it can said that this approach is very good \n",
    "approach to go forward for this classification problem.\n",
    "but you can argue that i took only 10000 of total data. But here i believe key step is preparing the corpus which will vary as per the size of total data. also if we look at the data and read through the two features additionalAttributes and breadcrumbs we can easily classify the label by looking at the components of these features. I believe this is what i incorporated in this approach the ability to look into components of these two features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# please let me know If you have any doubts or suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
